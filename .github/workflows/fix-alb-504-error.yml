name: Fix ALB 504 Gateway Timeout Error

on:
  workflow_dispatch:
    inputs:
      approach:
        description: 'Which approach to try first?'
        required: true
        default: 'simple'
        type: choice
        options:
        - simple
        - official-policy
        - complete-policy

env:
  AWS_REGION: 'us-east-1'
  CLUSTER_NAME: 'retail-store-cluster'
  ROLE_NAME: 'AmazonEKSLoadBalancerControllerRole'
  POLICY_NAME: 'AWSLoadBalancerControllerIAMPolicy'

jobs:
  fix-alb-issue:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig \
          --region ${{ env.AWS_REGION }} \
          --name ${{ env.CLUSTER_NAME }}

    - name: Check current ingress status
      id: check-current
      run: |
        echo "Checking current ingress status..."
        if kubectl get ingress retail-store-ingress --namespace=default > /dev/null 2>&1; then
          CURRENT_ALB=$(kubectl get ingress retail-store-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "none")
          echo "Current ALB hostname: $CURRENT_ALB"
          echo "exists=true" >> $GITHUB_OUTPUT
          echo "alb_hostname=$CURRENT_ALB" >> $GITHUB_OUTPUT
        else
          echo "exists=false" >> $GITHUB_OUTPUT
          echo "alb_hostname=none" >> $GITHUB_OUTPUT
        fi

    - name: Determine approach
      id: approach
      run: |
        echo "approach=${{ github.event.inputs.approach || 'simple' }}" >> $GITHUB_OUTPUT

    - name: Fix IAM Policy - Official AWS Policy
      if: steps.approach.outputs.approach == 'official-policy'
      run: |
        echo "Applying official AWS Load Balancer Controller policy..."
        
        # Download the official IAM policy
        curl -s -o iam-policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json
        
        # Create and attach the policy
        aws iam create-policy \
          --policy-name ${{ env.POLICY_NAME }} \
          --policy-document file://iam-policy.json 2>/dev/null || echo "Policy may already exist, continuing..."
        
        # Attach to role
        aws iam attach-role-policy \
          --role-name ${{ env.ROLE_NAME }} \
          --policy-arn arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:policy/${{ env.POLICY_NAME }}
        
        echo "Official AWS policy attached successfully"

    - name: Fix IAM Policy - Complete Custom Policy
      if: steps.approach.outputs.approach == 'complete-policy'
      run: |
        echo "Applying complete custom policy..."
        
        # Create the complete policy JSON file
        cat > complete-load-balancer-policy.json << EOF
        {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": [
                        "iam:CreateServiceLinkedRole",
                        "ec2:DescribeAccountAttributes",
                        "ec2:DescribeAddresses",
                        "ec2:DescribeAvailabilityZones",
                        "ec2:DescribeInternetGateways",
                        "ec2:DescribeVpcs",
                        "ec2:DescribeSubnets",
                        "ec2:DescribeSecurityGroups",
                        "ec2:DescribeInstances",
                        "ec2:DescribeNetworkInterfaces",
                        "ec2:DescribeTags",
                        "ec2:GetCoipPoolUsage",
                        "ec2:DescribeCoipPools",
                        "ec2:DescribeRouteTables",
                        "elasticloadbalancing:DescribeLoadBalancers",
                        "elasticloadbalancing:DescribeLoadBalancerAttributes",
                        "elasticloadbalancing:DescribeListeners",
                        "elasticloadbalancing:DescribeListenerCertificates",
                        "elasticloadbalancing:DescribeSSLPolicies",
                        "elasticloadbalancing:DescribeRules",
                        "elasticloadbalancing:DescribeTargetGroups",
                        "elasticloadbalancing:DescribeTargetHealth",
                        "elasticloadbalancing:DescribeTargetGroupAttributes",
                        "elasticloadbalancing:CreateLoadBalancer",
                        "elasticloadbalancing:CreateTargetGroup",
                        "elasticloadbalancing:CreateListener",
                        "elasticloadbalancing:DeleteListener",
                        "elasticloadbalancing:CreateRule",
                        "elasticloadbalancing:DeleteRule",
                        "elasticloadbalancing:DeleteLoadBalancer",
                        "elasticloadbalancing:DeleteTargetGroup",
                        "elasticloadbalancing:ModifyLoadBalancerAttributes",
                        "elasticloadbalancing:ModifyTargetGroup",
                        "elasticloadbalancing:ModifyTargetGroupAttributes",
                        "elasticloadbalancing:RegisterTargets",
                        "elasticloadbalancing:DeregisterTargets",
                        "elasticloadbalancing:SetWebAcl",
                        "elasticloadbalancing:ModifyListener",
                        "elasticloadbalancing:AddListenerCertificates",
                        "elasticloadbalancing:RemoveListenerCertificates",
                        "elasticloadbalancing:ModifyRule",
                        "elasticloadbalancing:AddTags",
                        "elasticloadbalancing:RemoveTags",
                        "elasticloadbalancing:SetIpAddressType",
                        "elasticloadbalancing:SetSecurityGroups",
                        "elasticloadbalancing:SetSubnets",
                        "cognito-idp:DescribeUserPoolClient",
                        "acm:ListCertificates",
                        "acm:DescribeCertificate",
                        "iam:ListServerCertificates",
                        "iam:GetServerCertificate",
                        "waf-regional:GetWebACL",
                        "waf-regional:GetWebACLForResource",
                        "waf-regional:AssociateWebACL",
                        "waf-regional:DisassociateWebACL",
                        "wafv2:GetWebACL",
                        "wafv2:GetWebACLForResource",
                        "wafv2:AssociateWebACL",
                        "wafv2:DisassociateWebACL",
                        "shield:GetSubscriptionState",
                        "shield:DescribeProtection",
                        "shield:CreateProtection",
                        "shield:DeleteProtection"
                    ],
                    "Resource": "*"
                }
            ]
        }
        EOF
        
        # Create and attach the policy
        aws iam create-policy \
          --policy-name AWSLoadBalancerControllerCompletePolicy \
          --policy-document file://complete-load-balancer-policy.json 2>/dev/null || echo "Policy may already exist, continuing..."
        
        aws iam attach-role-policy \
          --role-name ${{ env.ROLE_NAME }} \
          --policy-arn arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:policy/AWSLoadBalancerControllerCompletePolicy
        
        echo "Complete custom policy attached successfully"

    - name: Get Subnet Information
      run: |
        echo "Retrieving subnet information..."
        echo "Public subnets (tagged for ELB):"
        aws ec2 describe-subnets --region ${{ env.AWS_REGION }} \
          --filters "Name=tag:kubernetes.io/role/elb,Values=1" \
          --query 'Subnets[*].{ID:SubnetId,Name:Tags[?Key==`Name`].Value|[0],AZ:AvailabilityZone}' \
          --output table

    - name: Create Optimized Ingress Configuration
      run: |
        echo "Creating optimized ingress configuration..."
        
        cat > ingress-optimized.yaml << EOF
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        metadata:
          name: retail-store-ingress
          namespace: default
          annotations:
            kubernetes.io/ingress.class: alb
            alb.ingress.kubernetes.io/scheme: internet-facing
            alb.ingress.kubernetes.io/target-type: ip
            alb.ingress.kubernetes.io/healthcheck-path: /
            alb.ingress.kubernetes.io/healthcheck-protocol: HTTP
            alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}]'
            alb.ingress.kubernetes.io/subnet-type: public
            alb.ingress.kubernetes.io/healthcheck-interval-seconds: '15'
            alb.ingress.kubernetes.io/healthcheck-timeout-seconds: '5'
            alb.ingress.kubernetes.io/healthy-threshold-count: '2'
            alb.ingress.kubernetes.io/unhealthy-threshold-count: '2'
            alb.ingress.kubernetes.io/success-codes: '200,302'
            alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=60
        spec:
          rules:
            - http:
                paths:
                  - path: /
                    pathType: Prefix
                    backend:
                      service:
                        name: ui
                        port:
                          number: 80
          defaultBackend:
            service:
              name: ui
              port:
                number: 80
        EOF
        
        echo "Optimized ingress configuration created"

    - name: Restart Load Balancer Controller
      run: |
        echo "Restarting AWS Load Balancer Controller to pick up new permissions..."
        kubectl rollout restart deployment/aws-load-balancer-controller -n kube-system
        
        # Wait for controller to be ready
        echo "Waiting for controller to be ready..."
        kubectl wait --for=condition=ready pod \
          -n kube-system \
          -l app.kubernetes.io/name=aws-load-balancer-controller \
          --timeout=300s
        
        echo "Load Balancer Controller restarted successfully"

    - name: Apply or Update Ingress
      run: |
        echo "Applying optimized ingress configuration..."
        
        # Check if we need to create or update
        if kubectl get ingress retail-store-ingress --namespace=default > /dev/null 2>&1; then
          echo "Updating existing ingress..."
          kubectl apply -f ingress-optimized.yaml
        else
          echo "Creating new ingress..."
          kubectl apply -f ingress-optimized.yaml
        fi
        
        echo "Ingress configuration applied successfully"

    - name: Monitor ALB Provisioning
      id: monitor-alb
      run: |
        echo "Monitoring ALB provisioning (this may take 2-5 minutes)..."
        
        # Initial wait for ALB to start provisioning
        sleep 30
        
        # Monitor for up to 8 minutes
        for i in {1..48}; do
          echo "Status check $i/48..."
          
          # Get ingress details
          INGRESS_JSON=$(kubectl get ingress retail-store-ingress -o json 2>/dev/null || echo "{}")
          ALB_HOSTNAME=$(echo "$INGRESS_JSON" | jq -r '.status.loadBalancer.ingress[0].hostname // empty')
          ALB_STATE=$(echo "$INGRESS_JSON" | jq -r '.metadata.annotations["alb.ingress.kubernetes.io/state"] // "provisioning"')
          
          if [[ ! -z "$ALB_HOSTNAME" ]]; then
            echo "âœ… ALB is ready! Hostname: $ALB_HOSTNAME"
            echo "ALB_HOSTNAME=$ALB_HOSTNAME" >> $GITHUB_ENV
            echo "alb_ready=true" >> $GITHUB_OUTPUT
            break
          fi
          
          if [ $i -eq 48 ]; then
            echo "âš ï¸ ALB provisioning taking longer than expected"
            echo "alb_ready=false" >> $GITHUB_OUTPUT
          fi
          
          sleep 10
        done

    - name: Verify ALB Configuration
      run: |
        echo "=== ALB Configuration Verification ==="
        
        # Get detailed ingress information
        kubectl get ingress retail-store-ingress -o wide
        echo ""
        
        # Describe ingress for detailed status
        echo "Ingress description:"
        kubectl describe ingress retail-store-ingress
        echo ""

    - name: Check Load Balancer Controller Logs
      run: |
        echo "=== Load Balancer Controller Logs (last 20 lines) ==="
        kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=20 || echo "No logs available yet"

    - name: Test Application Connectivity
      if: env.ALB_HOSTNAME
      run: |
        echo "Testing application connectivity..."
        
        ALB_URL="http://$ALB_HOSTNAME"
        echo "Testing URL: $ALB_URL"
        
        # Test with retries and detailed output
        for i in {1..12}; do
          echo "Test attempt $i/12..."
          
          RESPONSE=$(curl -s -o /dev/null -w "HTTP_STATUS:%{http_code} TOTAL_TIME:%{time_total}s " \
            --connect-timeout 10 \
            --max-time 15 \
            $ALB_URL/ || echo "CONNECTION_FAILED")
          
          if [[ "$RESPONSE" == *"HTTP_STATUS:200"* ]] || [[ "$RESPONSE" == *"HTTP_STATUS:302"* ]]; then
            echo "âœ… SUCCESS: Application is responding correctly"
            echo "Response details: $RESPONSE"
            break
          elif [[ "$RESPONSE" == *"HTTP_STATUS:504"* ]]; then
            echo "âŒ Got 504 Gateway Timeout - ALB is still provisioning backend targets"
          elif [[ "$RESPONSE" == *"HTTP_STATUS:5"* ]]; then
            echo "âš ï¸ Server error: $RESPONSE"
          else
            echo "Attempt $i: $RESPONSE"
          fi
          
          if [ $i -eq 12 ]; then
            echo "âš ï¸ Application not fully responsive yet, but ALB is created."
            echo "This is normal - it may take a few more minutes for targets to register."
          fi
          
          sleep 10
        done

    - name: Final Status Report
      run: |
        echo "=== FINAL DEPLOYMENT STATUS ==="
        echo ""
        
        # Get current ingress status
        CURRENT_ALB=$(kubectl get ingress retail-store-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "Not available")
        echo "ðŸŒ ALB Hostname: $CURRENT_ALB"
        echo ""
        
        # Get application pod status
        echo "ðŸ“Š Application Pods:"
        kubectl get pods -l app=ui --namespace=default || echo "No UI pods found"
        echo ""
        
        # Get service status
        echo "ðŸ”— Service Status:"
        kubectl get service ui --namespace=default || echo "UI service not found"
        echo ""
        
        # Check if targets are healthy
        if [[ "$CURRENT_ALB" != "Not available" ]]; then
          echo "âœ… ALB has been successfully created/updated"
          echo "ðŸ“ Application URL: http://$CURRENT_ALB"
          echo ""
          echo "Note: It may take 2-5 minutes for the ALB to fully initialize and route traffic."
        else
          echo "â³ ALB is still provisioning. Check back in a few minutes."
        fi

    - name: Create Workflow Summary
      if: always()
      run: |
        echo "## ALB 504 Fix Deployment Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Deployment Approach:** ${{ steps.approach.outputs.approach }}" >> $GITHUB_STEP_SUMMARY
        echo "**Timestamp:** $(date -u)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Get final status
        FINAL_ALB=$(kubectl get ingress retail-store-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "Not available")
        echo "**ALB Hostname:** \`$FINAL_ALB\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "$FINAL_ALB" != "Not available" ]]; then
          echo "### âœ… Deployment Successful" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Application URL:** [http://$FINAL_ALB](http://$FINAL_ALB)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Next Steps:**" >> $GITHUB_STEP_SUMMARY
          echo "- The ALB may take 2-5 minutes to fully initialize" >> $GITHUB_STEP_SUMMARY
          echo "- Monitor the application at the URL above" >> $GITHUB_STEP_SUMMARY
          echo "- Check CloudWatch logs for any additional issues" >> $GITHUB_STEP_SUMMARY
        else
          echo "### âš ï¸ Deployment In Progress" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The ALB is still provisioning. This is normal and can take up to 10 minutes." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**What's happening:**" >> $GITHUB_STEP_SUMMARY
          echo "- IAM permissions have been updated" >> $GITHUB_STEP_SUMMARY
          echo "- Load Balancer Controller has been restarted" >> $GITHUB_STEP_SUMMARY
          echo "- Ingress configuration has been applied" >> $GITHUB_STEP_SUMMARY
          echo "- AWS is provisioning the Application Load Balancer" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "*Workflow run: $GITHUB_RUN_ID*" >> $GITHUB_STEP_SUMMARY
